# Rough Notes

## Day 04 | August 16, 2019 | Friday

So today after walking myself through the PySpark course on Udemy, I decided to start from the very basics - Basic Statistics course on Coursera. That’s the beauty of thepersonalMSDS, it gives you total autonomy to explore whatever intrigues you. Along the way I listened to some motivational content. I follow many influencers, but when it comes to “putting in the work” then Gary Vayverchuk is one of my favorites. Also, you can find a hell lot of content at Evan Charmichael’s Youtube channel [here](https://www.youtube.com/channel/UCKmkpoEqg1sOMGEiIysP8Tw)


Basic Statistics is paid - only If you what a certificate but you can always access the course content free by auditing the course. I really encourage that you buy the course but in case you’re a little low on the budget then go free and find the relevant coding exercises on Github.


Let’s start with variables and constants, variable is something that changes its value and constant remains the same throughout. There are different types of variables: nominal-categorical, ordinal-categorical, interval-quantitative and ratio-quantitative. Quantitative can either be discrete or continuous. We need to consider these levels of measurements while dealing with any kind of problem. Cases means Someone or something & Variable are the characteristics under consideration. Data Matrix is data in tabular format that serves as a source for all the data analysis.


A table in which a “count” value (or in statistical terms a “frequency”) is associated with each case is called a frequency table. It may also contain Relative frequency which is just the current frequency divided by the total number of cases. Sometimes we see Cumulative frequency which is basically frequencies of each case added-up to the subsequent case and so on. Sometimes it’s better to convert the quantitative variables into ordinal categorical variable for making frequency table much more useful - it’s called re-coding variables. Tables and graphs summarizes the dataset. Pie chart, Box-Plot, Dot-plot, Histogram and Bar-graphs can be used to present data. Histogram can be symmetric, skewed or contains two peaks. 


Measures of Central Tendency, are used to describe the center of distributions. Most common are Mean, Median and Mode. (Spoiler alert: we use these measures to fill-in the null entries in our dataset - this process falls under data wrangling or preprocessing). Measures of Dispersion or Variability of data include Range (a measure of variability in distribution) and Interquartile Range (similar to range but it ignores the extreme values / not affected by outliers). Quartiles, Deciles and Percentiles divide a set of data into four, ten or hundred equal parts.


Standard Deviation and Variance, (boy I could never actually understood what these are - now I do), the larger the variance the larger the variability. The metric of variable under analysis here is squared, in variance, hence we square-root it to get Standard deviation. Z-score tells us how extreme our observation is after standardizing the whole dataset. That’s all folks!


Questions: How do we find mode in the bimodal distribution? When do we prefer median over mean?
